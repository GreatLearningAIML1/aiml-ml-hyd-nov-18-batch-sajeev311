{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R8_External_Lab_Sajeev.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QGIsF1ADyJ58"
      },
      "source": [
        "# Transfer Learning CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E-n6tVFayGBe"
      },
      "source": [
        "* Train a simple convnet on the CIFAR dataset the first 5 output classes [0..4].\n",
        "* Freeze convolutional layers and fine-tune dense layers for the last 5 ouput classes [5..9].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cq8ejXHJyGYq"
      },
      "source": [
        "### 1. Import CIFAR10 data and create 2 datasets with one dataset having classes from 0 to 4 and other having classes from 5 to 9 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sH_XVfDy0FW",
        "colab_type": "code",
        "outputId": "a2211ec4-a8aa-4d12-8b30-8dfa53c647ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import datetime\n",
        "\n",
        "np.random.seed(42) \n",
        "import keras\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense, Dropout"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uWYbxnBayFUP",
        "colab": {}
      },
      "source": [
        "#import CIFAR10 dataset\n",
        "from keras.datasets import cifar10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsQPJ34jzTkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "now = datetime.datetime.now\n",
        "\n",
        "batch_size = 128\n",
        "nb_classes = 5\n",
        "nb_epoch = 5\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "# number of convolutional filters to use\n",
        "nb_filters = 32\n",
        "# size of pooling area for max pooling\n",
        "pool_size = 2\n",
        "# convolution kernel size\n",
        "kernel_size = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FyGWXFnzcfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G851KBszmAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_lt5 = x_train[y_train < 5]\n",
        "y_train_lt5 = y_train[y_train < 5]\n",
        "x_test_lt5 = x_test[y_test < 5]\n",
        "y_test_lt5 = y_test[y_test < 5]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xtCKmQh4yXhT"
      },
      "source": [
        "### 2. Use One-hot encoding to divide y_train and y_test into required no of output classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uN5O2kJ3yYa6",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cuOiKWfeybAl"
      },
      "source": [
        "### 3. Build a sequential neural network model which can classify the classes 0 to 4 of CIFAR10 dataset with at least 80% accuracy on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5HzxNbiiyoBD",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "woTfNst_ynRG"
      },
      "source": [
        "### 4. In the model which was built above (for classification of classes 0-4 in CIFAR10), make only the dense layers to be trainable and conv layers to be non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o_VCDB3Byb1a",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1-uUPqWpyeyX"
      },
      "source": [
        "### 5. Utilize the the model trained on CIFAR 10 (classes 0 to 4) to classify the classes 5 to 9 of CIFAR 10  (Use Transfer Learning) <br>\n",
        "Achieve an accuracy of more than 85% on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "szHjJgDvyfCt",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FU-HwvIdH0M-"
      },
      "source": [
        "## Sentiment analysis <br> \n",
        "\n",
        "The objective of the second problem is to perform Sentiment analysis from the tweets data collected from the users targeted at various mobile devices.\n",
        "Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nAQDiZHRH0M_"
      },
      "source": [
        "### 6. Read the dataset (tweets.csv) and drop the NA's while reading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwC07FxJp8c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6BOlw_Z1t5G",
        "colab_type": "code",
        "outputId": "b245c27f-c5f4-477d-8d63-d07500440736",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3eXGIe-SH0NA",
        "colab": {}
      },
      "source": [
        "df_Tweets = pd.read_csv('/content/gdrive/My Drive/Labs/tweets.csv', encoding = \"ISO-8859-1\").dropna()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CWeWe1eJH0NF",
        "outputId": "b49d5a6e-e3c8-477d-a603-9e9f9797be3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_Tweets.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3291, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7kX-WoJDH0NV",
        "outputId": "9042828c-24e1-40da-bdd7-288779b419bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_Tweets.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...                                   Negative emotion\n",
              "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...                                   Positive emotion\n",
              "2  @swonderlin Can not wait for #iPad 2 also. The...  ...                                   Positive emotion\n",
              "3  @sxsw I hope this year's festival isn't as cra...  ...                                   Negative emotion\n",
              "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...                                   Positive emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSj3Veug2Goe",
        "colab_type": "code",
        "outputId": "f084f107-3835-48cd-c862-3f2ff59de54d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "df_Tweets.describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3291</td>\n",
              "      <td>3291</td>\n",
              "      <td>3291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3282</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>RT @mention Marissa Mayer: Google Will Connect...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>3</td>\n",
              "      <td>946</td>\n",
              "      <td>2672</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "count                                                3291  ...                                               3291\n",
              "unique                                               3282  ...                                                  4\n",
              "top     RT @mention Marissa Mayer: Google Will Connect...  ...                                   Positive emotion\n",
              "freq                                                    3  ...                                               2672\n",
              "\n",
              "[4 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j72KKT2S2w0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_Tweets['text'] = df_Tweets.tweet_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljh60Fsf24OL",
        "colab_type": "code",
        "outputId": "0ab4f37b-f1c9-49f1-8b8b-bf5312ec2002",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_Tweets.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3291, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OGWB3P2WH0NY"
      },
      "source": [
        "### Consider only rows having Positive emotion and Negative emotion and remove other rows from the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNsN3ErSjQV6",
        "colab_type": "code",
        "outputId": "153d6523-857e-46d5-daac-a72c94d86212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "df_Tweets['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive emotion                      2672\n",
              "Negative emotion                       519\n",
              "No emotion toward brand or product      91\n",
              "I can't tell                             9\n",
              "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bdgA_8N2H0NY",
        "colab": {}
      },
      "source": [
        "df_Tweets = df_Tweets[(df_tweets['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Positive emotion') | (df_tweets['is_there_an_emotion_directed_at_a_brand_or_product'] == 'Negative emotion')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Jlu-reIH0Na",
        "outputId": "9ac01a42-d107-40c6-f069-cfd2298a64fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_Tweets.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3191, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClQPsAV5q1dH",
        "colab_type": "code",
        "outputId": "f2443b39-98ba-4d59-a5bf-43e16d71611c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        }
      },
      "source": [
        "df_Tweets.head(15)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
              "      <td>Android</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Beautifully smart and simple idea RT @madebyma...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>Beautifully smart and simple idea RT @madebyma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Counting down the days to #sxsw plus strong Ca...</td>\n",
              "      <td>Apple</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>Counting down the days to #sxsw plus strong Ca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Excited to meet the @samsungmobileus at #sxsw ...</td>\n",
              "      <td>Android</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>Excited to meet the @samsungmobileus at #sxsw ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Find &amp;amp; Start Impromptu Parties at #SXSW Wi...</td>\n",
              "      <td>Android App</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>Find &amp;amp; Start Impromptu Parties at #SXSW Wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Foursquare ups the game, just in time for #SXS...</td>\n",
              "      <td>Android App</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>Foursquare ups the game, just in time for #SXS...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Gotta love this #SXSW Google Calendar featurin...</td>\n",
              "      <td>Other Google product or service</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>Gotta love this #SXSW Google Calendar featurin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Great #sxsw ipad app from @madebymany: http://...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>Great #sxsw ipad app from @madebymany: http://...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>haha, awesomely rad iPad app by @madebymany ht...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "      <td>haha, awesomely rad iPad app by @madebymany ht...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>I just noticed DST is coming this weekend. How...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "      <td>I just noticed DST is coming this weekend. How...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           tweet_text  ...                                               text\n",
              "0   .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...  .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
              "1   @jessedee Know about @fludapp ? Awesome iPad/i...  ...  @jessedee Know about @fludapp ? Awesome iPad/i...\n",
              "2   @swonderlin Can not wait for #iPad 2 also. The...  ...  @swonderlin Can not wait for #iPad 2 also. The...\n",
              "3   @sxsw I hope this year's festival isn't as cra...  ...  @sxsw I hope this year's festival isn't as cra...\n",
              "4   @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...  @sxtxstate great stuff on Fri #SXSW: Marissa M...\n",
              "7   #SXSW is just starting, #CTIA is around the co...  ...  #SXSW is just starting, #CTIA is around the co...\n",
              "8   Beautifully smart and simple idea RT @madebyma...  ...  Beautifully smart and simple idea RT @madebyma...\n",
              "9   Counting down the days to #sxsw plus strong Ca...  ...  Counting down the days to #sxsw plus strong Ca...\n",
              "10  Excited to meet the @samsungmobileus at #sxsw ...  ...  Excited to meet the @samsungmobileus at #sxsw ...\n",
              "11  Find &amp; Start Impromptu Parties at #SXSW Wi...  ...  Find &amp; Start Impromptu Parties at #SXSW Wi...\n",
              "12  Foursquare ups the game, just in time for #SXS...  ...  Foursquare ups the game, just in time for #SXS...\n",
              "13  Gotta love this #SXSW Google Calendar featurin...  ...  Gotta love this #SXSW Google Calendar featurin...\n",
              "14  Great #sxsw ipad app from @madebymany: http://...  ...  Great #sxsw ipad app from @madebymany: http://...\n",
              "15  haha, awesomely rad iPad app by @madebymany ht...  ...  haha, awesomely rad iPad app by @madebymany ht...\n",
              "17  I just noticed DST is coming this weekend. How...  ...  I just noticed DST is coming this weekend. How...\n",
              "\n",
              "[15 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SotCRvkDH0Nf"
      },
      "source": [
        "### 7. Represent text as numerical data using `CountVectorizer` and get the document term frequency matrix\n",
        "\n",
        "#### Use `vect` as the variable name for initialising CountVectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YcbkY4sgH0Ng",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "Vect = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5pxd5fSHH0Nt"
      },
      "source": [
        "### 8. Find number of different words in vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS_dycK2606m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DTW = Vect.fit_transform(df_Tweets['tweet_text'])\n",
        "DTW = DTW.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfuqMqD7t_k1",
        "colab_type": "code",
        "outputId": "667e94fb-af0a-47b5-ad15-b63c77ca8dbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "DTW.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3191, 5648)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p1DQ2LdNH0Nu",
        "outputId": "441be74a-6c40-4af7-beac-8e2ada4d4bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "Words = Vect.get_feature_names()\n",
        "print(Words)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['000', '02', '03', '08', '10', '100', '100s', '100tc', '101', '106', '10am', '10k', '10mins', '10pm', '10x', '11', '11ntc', '11th', '12', '12b', '12th', '13', '130', '14', '1406', '1413', '1415', '15', '150', '1500', '150m', '157', '15am', '15k', '16162', '16gb', '16mins', '17', '188', '1986', '1990style', '1m', '1of', '1pm', '1st', '20', '200', '2010', '2011', '2012', '20s', '21', '22', '23', '24', '25', '250k', '25th', '2am', '2day', '2honor', '2moro', '2nd', '2nite', '2s', '2yrs', '30', '300', '3000', '30a', '30am', '30p', '30pm', '32', '32gb', '35', '36', '37', '3d', '3g', '3gs', '3k', '3rd', '3x', '40', '400', '40min', '41', '45', '45am', '47', '48', '4android', '4chan', '4g', '4nqv92l', '4sq', '4sq3', '4square', '50', '54', '55', '58', '59', '59p', '59pm', '5pm', '5th', '60', '64g', '64gb', '64gig', '64mb', '65', '6hours', '6th', '70', '75', '7th', '80', '800', '80s', '81', '82', '89', '8am', '8p', '8pm', '8th', '90', '900', '911tweets', '95', '96', '967', '97', '98', '99', '99å', '9th', '__', '______', '_______', '_ã', '_ô', 'a3xvwc6', 'aapl', 'abacus', 'abandoned', 'aber', 'ability', 'able', 'about', 'abroad', 'absolute', 'absolutely', 'abt', 'abuzz', 'academy', 'acc', 'acceptable', 'access', 'accessibility', 'accessible', 'accessories', 'accessory', 'accesssxsw', 'accommodate', 'according', 'accordion', 'account', 'acerbic', 'achieve', 'acknowledge', 'aclu', 'aclus', 'acquired', 'across', 'acrosse', 'action', 'actions', 'activate', 'activations', 'activity', 'actors', 'actsofsharing', 'actual', 'actually', 'ad', 'adam', 'adams', 'adapt', 'adaptive', 'add', 'added', 'addicted', 'addictedtotheinterwebs', 'addictive', 'addicts', 'adding', 'addition', 'additional', 'address', 'adfonic', 'admired', 'admission', 'admit', 'admits', 'admitting', 'ado', 'adopter', 'adopters', 'adoption', 'adpeopleproblems', 'ads', 'advanced', 'advent', 'adventure', 'advertising', 'advice', 'advisory', 'aesthetic', 'affair', 'affirmative', 'afford', 'afraid', 'africans', 'after', 'afternoon', 'again', 'against', 'agchat', 'agencies', 'agency', 'agenda', 'agents', 'agileagency', 'agnerd', 'ago', 'agree', 'agreed', 'ah', 'ahead', 'ahem', 'ahh', 'ahhh', 'ahing', 'aicn', 'aiding', 'aim', 'ain', 'air', 'airline', 'airlines', 'airplane', 'airport', 'airports', 'airs', 'ajs2011', 'aka', 'akqas', 'al', 'alamo', 'alan', 'alarm', 'alarms', 'alas', 'alcoholics', 'alert', 'alerts', 'alex', 'alive', 'all', 'allow', 'allowing', 'almost', 'alone', 'along', 'alot', 'alphagraphics', 'already', 'also', 'alt', 'alternate', 'alternative', 'although', 'always', 'alwayshavingtoplugin', 'am', 'amateurhour', 'amazing', 'amazingly', 'amazon', 'ambassador', 'america', 'amex', 'amigos', 'among', 'amount', 'amp', 'amused', 'amusing', 'an', 'analysis', 'analytics', 'and', 'andoid', 'andriod', 'andro', 'android', 'androidsxsw', 'angry', 'angrybirds', 'announce', 'announced', 'announces', 'announcing', 'annoyed', 'annoying', 'anoth', 'another', 'answer', 'answered', 'anti', 'anticipate', 'antigov', 'antique', 'antonio', 'antwoord', 'anxiety', 'anxious', 'any', 'anybody', 'anybodywanttobuymeanipad2', 'anymore', 'anyone', 'anyones', 'anything', 'anyway', 'anyways', 'anywhere', 'aos', 'ap', 'apac', 'apartment', 'api', 'apis', 'app', 'apparent', 'apparently', 'appcircus', 'appeal', 'appealing', 'appear', 'appears', 'applauds', 'applause', 'apple', 'apple_store', 'appleaddiction', 'appleatxdt', 'applefanatic', 'apples', 'appletakingoverworld', 'application', 'applications', 'appolicious', 'appreciate', 'appreciation', 'approach', 'approaches', 'approval', 'approved', 'approves', 'apps', 'aquent', 'arcade', 'archive', 'arctic', 'arduino', 'are', 'area', 'areas', 'aren', 'arg', 'argues', 'argument', 'aristotle', 'arm', 'armadillo', 'armed', 'aron', 'around', 'arrived', 'arrives', 'arriving', 'art', 'article', 'articles', 'articulate', 'artificial', 'artist', 'artistic', 'artists', 'artwork', 'artworks', 'arw', 'as', 'asddieu', 'ask', 'asked', 'asking', 'asleep', 'ass', 'assisted', 'assistivetech', 'assume', 'at', 'atari', 'atl', 'atms', 'atrix', 'att', 'attached', 'attempt', 'attend', 'attended', 'attendees', 'attending', 'attention', 'attitudes', 'attracted', 'attracting', 'attractive', 'atx', 'atzip', 'atåê', 'audience', 'audio', 'augcomm', 'augmented', 'augmentedreality', 'auntie', 'aus', 'austin', 'austincrowd', 'austinites', 'austintx', 'austinwins', 'australian', 'ausxsw', 'auth', 'authenticator', 'authorization', 'autistic', 'auto', 'autocorrect', 'autocorrects', 'autonomous', 'avail', 'available', 'ave', 'avenue', 'average', 'averages', 'avoid', 'avoiding', 'aw', 'awake', 'award', 'awards', 'aware', 'awareness', 'away', 'awe', 'awesome', 'awesomely', 'awesomeness', 'awesometiming', 'awhile', 'awkward', 'awwww', 'axzwxb', 'b4', 'baaah', 'baby', 'back', 'background', 'backlight', 'backpack', 'backup', 'backupify', 'bad', 'badge', 'badgeless', 'badges', 'bag', 'bags', 'bahahahaha', 'bajillions', 'balance', 'balckberries', 'balcony', 'ball', 'ballroom', 'ballrooms', 'banality', 'band', 'bands', 'bandwaggoners', 'bandwidth', 'bang', 'banged', 'bank', 'banking', 'bankinnovate', 'bankinnovation', 'banks', 'bar', 'barcode', 'barely', 'barring', 'barroom', 'barry', 'barrydiller', 'bars', 'bart', 'barton', 'based', 'bashing', 'basic', 'basically', 'basics', 'basis', 'basket', 'bastards', 'bat', 'bathroom', 'batphone', 'batt', 'batteries', 'battery', 'batterykiller', 'battle', 'battledecks', 'battlela', 'bavcid', 'bawling', 'bb', 'bbq', 'bc', 'bday', 'be', 'beach', 'beans', 'bear', 'beard', 'beat', 'beats', 'beautiful', 'beautifully', 'beauty', 'because', 'become', 'becoming', 'bed', 'beechwood', 'been', 'beer', 'before', 'beforetwitter', 'begin', 'beginning', 'begins', 'behance', 'behave', 'behaving', 'behavior', 'behind', 'being', 'believe', 'belinsky', 'belong', 'beluga', 'ben', 'benefit', 'benieuwd', 'bereft', 'bergstrom', 'berklee', 'bernd', 'berry', 'best', 'bestappever', 'bestie', 'bet', 'beta', 'betainvites', 'better', 'bettercloud', 'bettersearch', 'betterthingstodo', 'between', 'beware', 'beyond', 'bff', 'bicycle', 'big', 'bigger', 'biggest', 'bike', 'billion', 'bin', 'bing', 'biomimicry', 'bird', 'birds', 'birth', 'birthday', 'bit', 'bite', 'biz', 'bizzy', 'bjdproductions', 'black', 'blackberry', 'blackbook', 'blacked', 'blame', 'blast', 'bleed', 'blew', 'blind', 'blinksale', 'block', 'blocked', 'blocking', 'blocks', 'blog', 'bloggable', 'blogger', 'blogging', 'blogs', 'bloody', 'bloomberg', 'blows', 'blue', 'blueray', 'bluetooth', 'bluezoom', 'blurs', 'bmm', 'bnet', 'board', 'boarded', 'body', 'bomb', 'boo', 'book', 'bookbook', 'books', 'boom', 'boomers', 'boost', 'booth', 'boots', 'booyah', 'booze', 'borderstylo', 'bored', 'born', 'borrow', 'borrowing', 'boss', 'botch', 'both', 'bother', 'bots', 'bottom', 'bought', 'bounced', 'bound', 'boundaries', 'bout', 'bowl', 'box', 'boxee', 'boxes', 'boy', 'boyfriend', 'boys', 'bpm', 'bracket', 'brah', 'brain', 'brains', 'brainwashed', 'brand', 'branded', 'brands', 'bravo', 'brawls', 'brazil', 'bread', 'break', 'breakdown', 'breakfast', 'breaking', 'breakout', 'breakthrough', 'breathtaking', 'breeds', 'brian_lam', 'brick', 'bricklin', 'bridging', 'bright', 'brightens', 'brightness', 'brilliance', 'brilliant', 'bring', 'bringing', 'brings', 'brisk', 'british', 'brits', 'brk', 'bro', 'broadcast', 'broadcastr', 'broadfeed', 'broken', 'brother', 'brought', 'browse', 'browser', 'browserwars', 'browsing', 'bruises', 'brushstroke', 'bryce', 'bt', 'btw', 'bubble', 'bucket', 'buffalo', 'bug', 'bugger', 'buggy', 'bugs', 'build', 'building', 'buildings', 'built', 'bulletin', 'bummed', 'bummer', 'bumped', 'bunch', 'burn', 'bursts', 'bus', 'busdev', 'business', 'businesses', 'busy', 'but', 'butt', 'button', 'buttons', 'butts', 'buy', 'buyers', 'buying', 'buys', 'buzz', 'buzzing', 'by', 'bynd', 'ca', 'cab', 'cabbies', 'cable', 'cables', 'cabs', 'cactus', 'cake', 'calendar', 'calhoun', 'california', 'call', 'callay', 'callback', 'called', 'callooh', 'calls', 'calyp', 'cam', 'came', 'camera', 'cameras', 'campaigns', 'campbell', 'campus', 'can', 'canada', 'canadian', 'cancel', 'cannot', 'cant', 'canvas', 'capabilities', 'capitol', 'capped', 'captain', 'capture', 'captured', 'car', 'caramel', 'carbon', 'card', 'cards', 'care', 'career', 'caring', 'carroll', 'carry', 'carrying', 'cart', 'cartel', 'cartoon', 'cartoonishly', 'case', 'cases', 'cash', 'cashmere', 'cashmore', 'cast', 'castle', 'casually', 'cat', 'catch', 'catching', 'catphysics', 'cattle', 'cause', 'caused', 'causing', 'cautiously', 'cbatsxsw', 'cc', 'cedar', 'celebrate', 'celebrating', 'celebs', 'cell', 'cellular', 'center', 'centers', 'central', 'centre', 'cents', 'ceo', 'ceokidschat', 'cera', 'cerebellum', 'cerebral', 'certain', 'certificate', 'ces', 'chain', 'chair', 'chalked', 'challenge', 'challenged', 'challenges', 'champ', 'chance', 'chances', 'change', 'changed', 'changer', 'changes', 'changing', 'channel', 'channels', 'chaos', 'characters', 'charge', 'charged', 'charger', 'chargers', 'charges', 'chargin2diffphonesatonce', 'charging', 'charity', 'charles', 'charm', 'charts', 'chat', 'chatter', 'chatting', 'cheapen', 'cheaper', 'check', 'checked', 'checking', 'checkins', 'checkout', 'cheeky', 'cheer', 'cheers', 'cheese', 'chen', 'chevy', 'chevysmc', 'chevysxsw', 'chevytweethouse', 'chic', 'chief', 'child', 'childhood', 'chill', 'chilltab', 'china', 'chinese', 'chip', 'chk', 'chng', 'choice', 'chokes', 'choose', 'choplifter', 'choreography', 'chris', 'christian', 'christmas', 'chrome', 'chromeos', 'chronicling', 'chumps', 'chunky', 'chìáo', 'cigarettes', 'cinema', 'circle', 'circles', 'circusmash', 'cited', 'cites', 'city', 'ck', 'cks', 'claims', 'clarity', 'clark', 'class', 'classics', 'classiest', 'classy', 'cle', 'clean', 'clear', 'clearly', 'cleveland', 'clever', 'click', 'clicked', 'client', 'clients', 'climbing', 'clipcon', 'clocks', 'close', 'closed', 'closely', 'closer', 'clothes', 'cloud', 'cloudapp', 'cloudsight', 'clumsily', 'cluster', 'cluttering', 'cm48', 'cmswire', 'cmty', 'cnet', 'cnn', 'cnngrill', 'cnnmoney', 'cnnmoneysxsw', 'cnt', 'cntr', 'co', 'cobra', 'cocaine', 'cocky', 'cocoon', 'code', 'coded', 'coders', 'coding', 'coffee', 'cohen', 'coincide', 'coincides', 'cold', 'colin', 'collab', 'collection', 'collective', 'collectively', 'color', 'colors', 'colour', 'com', 'combine', 'combines', 'comcom', 'come', 'comedy', 'comers', 'comes', 'comfort', 'comfortable', 'coming', 'commandeered', 'comment', 'comments', 'common', 'comms', 'communal', 'communicate', 'communication', 'communications', 'community', 'comp', 'compan', 'companies', 'company', 'compared', 'compatible', 'compels', 'compete', 'competition', 'competitor', 'competitors', 'compiling', 'complement', 'complete', 'completely', 'complex', 'complicated', 'composed', 'computer', 'computers', 'computing', 'concentrate', 'concept', 'concert', 'concertgoers', 'condense', 'conf', 'conference', 'conferences', 'confession', 'configuration', 'confines', 'confirmed', 'conflagration', 'confusion', 'congrats', 'congratulation', 'congratulations', 'congress', 'connect', 'connected', 'connectedbrands', 'connectedcar', 'connectedtv', 'connectivity', 'connects', 'conquered', 'consciously', 'considering', 'consistent', 'consistently', 'constant', 'consultation', 'consulting', 'consume', 'consumer', 'consumerist', 'consumerization', 'cont', 'contact', 'content', 'contentrules', 'contest', 'context', 'contextual', 'continued', 'continues', 'continuous', 'continuum', 'control', 'controller', 'conv', 'convenient', 'conveniently', 'convention', 'conventions', 'converge', 'conversation', 'conversations', 'conversion', 'convience', 'convince', 'convinced', 'convore', 'cool', 'cooler', 'coolest', 'coolhaus', 'coordinate', 'cope', 'copia', 'copper', 'cops', 'copy', 'cor', 'cord', 'cordless', 'cords', 'core', 'corner', 'corporate', 'corporation', 'corralling', 'correct', 'correcting', 'corrupted', 'cost', 'costume', 'couch', 'couchfan', 'cough', 'could', 'couldn', 'count', 'counting', 'country', 'couple', 'coupons', 'course', 'courtesy', 'courtside', 'courtyard', 'cover', 'coverage', 'covered', 'covering', 'covet', 'cow', 'cowboy', 'coworkers', 'cpa', 'cr', 'crack', 'crackberry', 'crafty', 'crap', 'crapkit', 'crapped', 'crappy', 'craps', 'crash', 'crashed', 'crasher', 'crashes', 'crashing', 'crashy', 'crave', 'craving', 'craziness', 'crazy', 'crazyco', 'crazyfest', 'cream', 'create', 'created', 'creates', 'creating', 'creative', 'creatively', 'creativity', 'creator', 'creatures', 'credit', 'creek', 'creeper', 'crew', 'cried', 'crippling', 'crisis', 'critiques', 'cross', 'crossed', 'crossing', 'crowd', 'crowdbeacon', 'crowded', 'crowds', 'crowdsourcing', 'crowley', 'crunch', 'crushing', 'crushit', 'cruze', 'cry', 'csr', 'cstejas', 'csuitecsourcing', 'ctia', 'cult', 'culture', 'cunning', 'cup', 'cupcake', 'cupertino', 'cups', 'curated', 'curatedebate', 'curiosity', 'curious', 'current', 'curse', 'cursing', 'cursor', 'custom', 'custome', 'customer', 'customers', 'cut', 'cute', 'cuts', 'cutsies', 'cuz', 'cwc2011', 'cwebb', 'cynical', 'dah', 'dahl', 'daily', 'dairy', 'dali', 'damage', 'damm', 'dammit', 'damn', 'damon', 'dan', 'dance', 'dancing', 'dandy', 'danfung', 'dang', 'dangerous', 'daniel', 'danny', 'dark', 'darn', 'darryl', 'das', 'dat', 'data', 'database', 'date', 'dating', 'david', 'davis', 'dawdled', 'dawg', 'dawn', 'day', 'daylight', 'days', 'de', 'dead', 'deadline', 'deadly', 'deal', 'dealing', 'deals', 'dear', 'death', 'debating', 'debut', 'debuting', 'debuts', 'decade', 'decent', 'decide', 'decided', 'deciding', 'decision', 'deck', 'dedication', 'deeper', 'def', 'default', 'deficit', 'define', 'defining', 'definitely', 'deforestation', 'degrees', 'dehumanizing', 'delay', 'delayed', 'delegates', 'delete', 'deleting', 'delicious', 'deliciously', 'deliciousness', 'delight', 'delightful', 'deliver', 'delivered', 'delivery', 'dell', 'delving', 'demand', 'demo', 'democracy', 'demoed', 'demoing', 'demonstrate', 'demonstrates', 'demonstration', 'denies', 'dennis', 'denotes', 'dense', 'density', 'depeche', 'depressed', 'described', 'design', 'designed', 'designers', 'designflaws', 'designing', 'designingforkids', 'desk', 'desktop', 'desktops', 'desperate', 'desperately', 'despite', 'destroyed', 'detail', 'detailed', 'details', 'detect', 'detection', 'dev', 'develop', 'developed', 'developer', 'developers', 'developing', 'development', 'deviantart', 'device', 'devices', 'devs', 'dexteria', 'dfcbto', 'dfp', 'dfw', 'dgtltribe', 'diabetes', 'dictaphone', 'dictatorship', 'did', 'didn', 'die', 'died', 'diego', 'dieing', 'dies', 'diet', 'diferencia', 'diff', 'difference', 'different', 'dig', 'digg', 'digging', 'digibiz', 'digital', 'digitally', 'dilemma', 'diller', 'dimensional', 'dine', 'dinner', 'direct', 'direction', 'directions', 'director', 'directors', 'dirty', 'dis', 'disabilities', 'disagree', 'disappointed', 'disappointingly', 'disaster', 'disc', 'discotalk', 'discover', 'discovered', 'discovery', 'discovr', 'discuss', 'discusses', 'discussion', 'disgraceful', 'disgusted', 'dislike', 'disliking', 'disney', 'disneyland', 'display', 'displaying', 'disrupt', 'disruptive', 'disrupts', 'dissapointment', 'distance', 'distribution', 'disturbing', 'ditch', 'divasanddorks', 'divide', 'dividends', 'dj', 'djroe', 'dk', 'dl', 'dm', 'do', 'doc', 'dock', 'docomo', 'docs', 'documented', 'documents', 'dodgeball', 'dodo', 'does', 'doesdroid', 'doesn', 'dog', 'dogs', 'doing', 'dokobots', 'dollar', 'dollars', 'dom', 'domain', 'dominance', 'domo', 'don', 'donate', 'donates', 'donating', 'done', 'dongle', 'donline', 'dont', 'dontbehatin', 'doo', 'doodle', 'doodles', 'doofusness', 'door', 'dorkinout', 'dotco', 'double', 'doubly', 'doubt', 'douche', 'douchebag', 'douchebaggery', 'dow', 'down', 'download', 'downloaded', 'downloading', 'downloads', 'downside', 'downstairs', 'downtown', 'dr_black', 'drafthouse', 'drag', 'draining', 'draw', 'drawing', 'draws', 'dream', 'dreams', 'drink', 'drinks', 'drive', 'driven', 'drivers', 'drives', 'driving', 'droid', 'drooling', 'drop', 'dropped', 'dropping', 'drowning', 'drug', 'drumroll', 'drupalcon', 'dst', 'dt', 'dtas', 'ducks', 'dude', 'due', 'duh', 'duking', 'dumped', 'dunno', 'durable', 'during', 'dwindled', 'dwindling', 'dyac', 'dynamic', 'dynamics', 'ea1zgd', 'each', 'eagerly', 'earbud', 'earbuds', 'earlier', 'early', 'earned', 'earphones', 'earplugs', 'ears', 'earth', 'earthhour', 'earthquake', 'earths', 'easeljs', 'easier', 'easy', 'eat', 'eatdrinktweet', 'eating', 'eats', 'ebay', 'ebooks', 'echofon', 'ecodriving', 'economy', 'ecosystem', 'edible', 'edition', 'edtech', 'education', 'educational', 'eff', 'effective', 'efficient', 'effing', 'effort', 'efforts', 'eg', 'egomaniacs', 'eh', 'either', 'elbow', 'election', 'electronics', 'elegant', 'elements', 'elevate', 'elevation', 'elonsxsw', 'else', 'email', 'emails', 'embarrassed', 'emc', 'eminent', 'emotional', 'employee', 'employees', 'empowered', 'empty', 'emulates', 'enable', 'enables', 'enabling', 'enchanted', 'enchanting', 'enchantment', 'end', 'endeavor', 'ended', 'endorsed', 'endorsement', 'ends', 'energy', 'engage', 'engage365', 'engagement', 'engaging', 'engine', 'engineer', 'engines', 'english', 'enhancements', 'enjoy', 'enjoyed', 'enjoying', 'enjoys', 'enlightening', 'enough', 'ensue', 'enter', 'entered', 'enterprise', 'entertaining', 'entire', 'entirely', 'entrepreneur', 'entry', 'enuf', 'enviro', 'environment', 'environmental', 'envisioning', 'envy', 'epic', 'epicenter', 'epicurious', 'equity', 'er', 'era', 'eric', 'error', 'ers', 'escape', 'esp', 'especially', 'essential', 'essentially', 'essentials', 'estate', 'et', 'etc', 'etch', 'etsbzk', 'etsy', 'europe', 'eurosxsw', 'evade', 'evaporation', 'even', 'evening', 'event', 'eventbrite', 'eventprofs', 'events', 'eventseekr', 'eventually', 'ever', 'everbody', 'evernote', 'every', 'everybody', 'everyday', 'everyone', 'everything', 'everytime', 'everywhere', 'evidence', 'evil', 'evo', 'evolving', 'evolvingworkplace', 'ex', 'exactly', 'example', 'examples', 'excellent', 'except', 'exceptionally', 'exchange', 'excited', 'excitement', 'exciting', 'excludes', 'exclusive', 'excuse', 'executed', 'executing', 'exhibit', 'exhibitors', 'exist', 'existence', 'existent', 'exists', 'expansion', 'expect', 'expectation', 'expected', 'expecting', 'expensive', 'experience', 'experiential', 'experiment', 'experimenting', 'expert', 'experts', 'expierence', 'explaining', 'explanation', 'exploiting', 'explorer', 'explorers', 'exploring', 'exported', 'exposing', 'express', 'exquisite', 'extended', 'extenders', 'extra', 'extraordinary', 'extras', 'eyeballed', 'eyes', 'f6bcet', 'fab', 'fab5', 'fabulous', 'face', 'facebook', 'facepalmed', 'facetime', 'facing', 'facist', 'fact', 'factor', 'facts', 'fades', 'fail', 'failed', 'failing', 'failure', 'fair', 'fake', 'false', 'fam', 'familiarize', 'famous', 'fan', 'fanboy', 'fanboyism', 'fanboys', 'fancrazed', 'fandango', 'fans', 'fantastic', 'fantastico', 'far', 'farm', 'farmers', 'farmville', 'farooqui', 'fascinating', 'fascist', 'fashion', 'fast', 'fastcompanygrill', 'fastcompanygrille', 'faster', 'fastest', 'fastsociety', 'fat', 'fathom', 'faulty', 'fav', 'fave', 'favorite', 'favorited', 'favorites', 'favour', 'fawning', 'fb', 'fear', 'feature', 'featured', 'features', 'featuring', 'feckin', 'fed', 'feed', 'feeding', 'feel', 'feelin', 'feeling', 'feelings', 'feels', 'fees', 'fell', 'fellow', 'fellowship', 'felt', 'ferris', 'ferriss', 'fessing', 'fest', 'festgoers', 'festival', 'festivalexplorer', 'festivalgenius', 'fetishism', 'few', 'ff', 'fh', 'fi', 'field', 'fiendishly', 'fight', 'fighting', 'figure', 'figuring', 'fill', 'filling', 'film', 'filmaster', 'filming', 'filter', 'filters', 'fin', 'final', 'finalist', 'finalists', 'finally', 'finals', 'find', 'finder', 'finding', 'fine', 'finger', 'fingerprint', 'fingers', 'finished', 'fire', 'first', 'firstworldproblems', 'fishing', 'fists', 'fit', 'fits', 'five', 'fives', 'fiving', 'fix', 'fixing', 'flaming', 'flannel', 'flash', 'flashspecial', 'flask', 'flavor', 'flaw', 'flawless', 'fleets', 'flew', 'flight', 'flights', 'flip', 'flipboard', 'floating', 'flocking', 'flood', 'floor', 'flop', 'florian', 'flow', 'fludapp', 'fluid', 'flummoxed', 'fly', 'flying', 'flypost', 'fmsignal', 'focus', 'focuses', 'focusing', 'fogo', 'foing', 'folks', 'follow', 'followed', 'followers', 'following', 'followings', 'fond', 'fondling', 'fonts', 'food', 'foodies', 'foodspotting', 'fools', 'foosspotting', 'foot', 'footage', 'footnotes', 'for', 'forbes', 'forbidden', 'force', 'forecast', 'forests', 'forever', 'forget', 'forgo', 'forgot', 'forgotten', 'form', 'format', 'formation', 'former', 'formerly', 'formula', 'forward', 'foster', 'found', 'four', 'foursquare', 'fr', 'frabjous', 'fragmentation', 'franchised', 'francisco', 'franco', 'frank', 'franken', 'freak', 'freaking', 'free', 'freespeech', 'freeze', 'frenzy', 'fresh', 'fri', 'frickin', 'fricking', 'frid', 'friday', 'friend', 'friendly', 'friends', 'frm', 'from', 'front', 'frontend', 'frood', 'frostwire', 'frothy', 'frozen', 'fruit', 'frustrated', 'frustrating', 'frustration', 'ft', 'ftp', 'ftw', 'fuck', 'fucking', 'fuckit', 'fuckyeah', 'fuel', 'full', 'fulltime', 'fully', 'fun', 'function', 'functions', 'fundraising', 'funny', 'fusion', 'future', 'futurecast', 'futuremf', 'futureoftouch', 'fwd', 'fxsw', 'fyi', 'fì_r', 'g03mzb', 'g2', 'g4gzypv', 'gabacustweets', 'gadget', 'gadgetenvy', 'gadgets', 'gadgetzilla', 'gaga', 'gah', 'galaxy', 'gallery', 'game', 'gamechanger', 'gamelayer', 'games', 'gamesfortv', 'gamestorming', 'gaming', 'gap', 'garageband', 'garyvee', 'gas', 'gasps', 'gatekeeper', 'gathering', 'gave', 'gawking', 'gay', 'gayno', 'gb', 'gear', 'gecko', 'gee', 'geek', 'geekdate', 'geekdilemma', 'geekdom', 'geekery', 'geekest', 'geekfest', 'geeking', 'geekout', 'geeks', 'geekspringbreak', 'geeksrule', 'geeky', 'gen', 'general', 'generally', 'generated', 'generations', 'generous', 'genius', 'geniuses', 'gents', 'geo', 'geogames', 'geolocation', 'germ', 'gesture', 'get', 'getjarsxsw', 'gets', 'getting', 'gettinng', 'giant', 'gibson', 'giddy', 'gift', 'gig', 'giggle', 'gigs', 'gilt', 'ginger', 'girl', 'girlcrush', 'girls', 'git', 'gitchococktailon', 'give', 'giveaway', 'giveaways', 'given', 'gives', 'giving', 'glad', 'glass', 'glasses', 'glenda', 'glimpse', 'global', 'globalbestaward', 'globally', 'glow', 'glowing', 'glued', 'gmail', 'go', 'go2', 'god', 'goddamn', 'godsend', 'goer', 'goers', 'goes', 'gogglers', 'goggles', 'gogo', 'goin', 'going', 'gold', 'golds', 'gone', 'gonna', 'gonnagetanipad2', 'goo', 'good', 'goodcustomerservice', 'gooddeed', 'goodguide', 'goodness', 'goody', 'goog', 'google', 'googleblog', 'googlebread', 'googlecircles', 'googled', 'googledoodle', 'googledoodles', 'googlegays', 'googleio', 'googlemaps', 'googleplaces', 'googletv', 'goona', 'got', 'gotta', 'gotten', 'gotto', 'government', 'govt', 'gowalla', 'gps', 'gr2l2', 'gr8', 'grab', 'grabbed', 'grabs', 'gram', 'gran', 'grand', 'grant', 'granted', 'grape', 'graph', 'graphic', 'graphics', 'grateful', 'gratification', 'great', 'greater', 'greatergood', 'greatest', 'greet', 'greeted', 'griddler', 'griffin', 'grill', 'grille', 'grindr', 'grn7pk', 'grooving', 'ground', 'group', 'groupchatapps', 'grouped', 'groupme', 'groupon', 'groups', 'grow', 'growing', 'grown', 'grrr', 'grrrr', 'grumbling', 'gsd', 'gsdm', 'gswsxsw', 'gt', 'guard', 'guardian', 'guards', 'guess', 'guessing', 'guest', 'guguchu', 'guide', 'guides', 'guild', 'guilty', 'guitar', 'gun', 'guru', 'guy', 'guykawasaki', 'guys', 'gvlrin', 'gym', 'h264', 'h2o', 'h4ckers', 'ha', 'habits', 'hack', 'hackathon', 'hacker', 'hackers', 'hacknews', 'had', 'hah', 'haha', 'hairy', 'haiti', 'half', 'halfway', 'hall', 'halls', 'hallway', 'hamsandwich', 'hand', 'handicapped', 'handing', 'handle', 'handled', 'hands', 'handset', 'handsome', 'handwriting', 'handy', 'hang', 'hanging', 'hangover', 'hangover3', 'hannukah', 'happen', 'happened', 'happening', 'happiest', 'happily', 'happy', 'happydance', 'hard', 'harlow', 'harnessing', 'harris', 'has', 'hash', 'hashable', 'hashtag', 'hashtags', 'hasn', 'hassle', 'hate', 'hated', 'haul', 'hauling', 'have', 'haven', 'havent', 'having', 'havnt', 'hawk', 'hawt', 'haystack', 'haz', 'hcsm', 'hdmi', 'he', 'head', 'headaches', 'headed', 'heading', 'headline', 'headphones', 'heads', 'headsets', 'health2dev', 'hear', 'heard', 'hearing', 'heart', 'heat', 'heating', 'heatmap', 'heats', 'heattracker', 'heavenly', 'heavens', 'heavier', 'heck', 'held', 'hell', 'hello', 'help', 'helped', 'helpful', 'helping', 'helps', 'her', 'here', 'hereforwork', 'herself', 'hey', 'heyo', 'hhaha', 'hhrs', 'hi', 'hidden', 'hide', 'high', 'higher', 'highlight', 'highlights', 'highly', 'hijack', 'hilarious', 'hill', 'hilton', 'him', 'hint', 'hints', 'hip', 'hipstamatic', 'hipster', 'hipstermuch', 'hipsters', 'hire', 'hireme', 'hirer', 'his', 'hiss', 'history', 'hisxsw', 'hit', 'hitlantis', 'hive', 'hls', 'hm', 'hmm', 'hmmm', 'hmmzies', 'hobo', 'hoc', 'hold', 'holding', 'hole', 'holla', 'holler', 'hollergram', 'hollow', 'hollrback', 'hollywood', 'holy', 'holytrafficjams', 'home', 'homeless', 'homepage', 'honesty', 'honor', 'honors', 'hoo', 'hook', 'hooked', 'hoooooooooooooo', 'hooray', 'hoot', 'hooting', 'hootsuite', 'hop', 'hope', 'hopefully', 'hopes', 'hoping', 'hopkins', 'hordes', 'horrendous', 'horrible', 'horror', 'hosted', 'hosting', 'hot', 'hotel', 'hotels', 'hotpot', 'hotspot', 'hottest', 'hour', 'hours', 'house', 'housing', 'how', 'howdy', 'howmto', 'hp', 'hpsxsw', 'hr', 'hrs', 'ht', 'htdfim', 'html', 'html5', 'htt', 'http', 'https', 'hubby', 'huge', 'human', 'hundred', 'hundreds', 'hunger', 'hungry', 'hunt', 'hunts', 'hurricaneparty', 'hurt', 'husband', 'huzzah', 'hyatt', 'hype', 'hyped', 'i41h53', 'ia', 'iads', 'ical', 'icanhas', 'ice', 'icebreaker', 'iconbuffet', 'id', 'id420666439', 'idea', 'ideally', 'ideas', 'identity', 'idiocy', 'idiot', 'idk', 'idol', 'idontbelieve', 'ie', 'ie9', 'ieavob', 'if', 'ifrom', 'ignite', 'ignore', 'igottagetit', 'ihop', 'il', 'illa', 'illegal', 'illmakeitwork', 'iloveasurprise', 'im', 'imac', 'imacs', 'image', 'images', 'imagine', 'imanidiot', 'imanoutcast', 'imho', 'immersive', 'immobile', 'imo', 'imp1000', 'impact', 'impactdashboard', 'impediment', 'impedimenta', 'implement', 'implementation', 'implementing', 'implode', 'important', 'impossible', 'impressed', 'impression', 'impressions', 'impressive', 'impromptu', 'improve', 'improvement', 'improvements', 'improvemnt', 'impulse', 'impulsive', 'imrich', 'imthatgood', 'in', 'inane', 'inbox', 'incapable', 'incenticize', 'incl', 'include', 'included', 'includes', 'including', 'incorrect', 'increase', 'incredible', 'incredibly', 'inde', 'indicates', 'indigenous', 'individuals', 'indoor', 'industry', 'infektd', 'inferior', 'influence', 'influencers', 'influx', 'info', 'informal', 'information', 'informed', 'ing', 'ingenious', 'initial', 'initiative', 'ink', 'innacurate', 'inner', 'innotribe', 'innovate', 'innovating', 'innovation', 'innovative', 'innovators', 'input', 'ins', 'insane', 'insanely', 'insatiable', 'insertion', 'inside', 'insider', 'insidious', 'insight', 'insightful', 'insights', 'insists', 'inspiring', 'instagram', 'install', 'installed', 'installing', 'installs', 'instant', 'instantly', 'instead', 'instruments', 'integrated', 'integration', 'intel', 'intelligence', 'intelligent', 'intended', 'intense', 'intentionally', 'interact', 'interactive', 'interested', 'interesting', 'interface', 'interfaces', 'intermittent', 'international', 'internet', 'internetonlinewebsite', 'interrupt', 'interview', 'interviewed', 'intimate', 'intimidated', 'into', 'intrestin', 'intricate', 'intriguing', 'intro', 'introduced', 'introduces', 'intrvw', 'invades', 'inventing', 'inventory', 'invest', 'investment', 'investor', 'investors', 'invisible', 'invite', 'invited', 'invites', 'invoking', 'io', 'ios', 'ip', 'ip4', 'ipad', 'ipad1', 'ipad2', 'ipad2s', 'ipad2time', 'ipad_2', 'ipaddesignheadaches', 'ipading', 'ipadmadness', 'ipads', 'iphone', 'iphone4', 'iphone5', 'iphones', 'ipod', 'ipods', 'ipoo', 'iqlab', 'iradar', 'irelay', 'ireport', 'iron', 'ironic', 'irrelevant', 'is', 'isack', 'ischafer', 'isn', 'issue', 'issues', 'istache', 'istock', 'it', 'item', 'its', 'itself', 'ittttt', 'itunes', 'itwillbemine', 'iusxsw', 'iwantacameraonmyipad', 'jailbreak', 'jaloux', 'james', 'jammy', 'janecek', 'japan', 'japanese', 'jared', 'java', 'javascript', 'jaw', 'jcpenney', 'jealous', 'jeanne', 'jeans', 'jeebus', 'jeez', 'jeff', 'jerk', 'jerranalley', 'jessedee', 'jet', 'jetsons', 'jinx', 'jk', 'job', 'jobs', 'jobs_co', 'jobsco', 'joe', 'johnston', 'join', 'joined', 'joke', 'jonathan', 'joomla', 'jose', 'josh', 'journal', 'journalists', 'journalsim', 'journey', 'joy', 'jpmobilesummit', 'jqtouch', 'jr', 'js', 'judging', 'juice', 'juiced', 'juicepack', 'julian', 'julie', 'jump', 'june', 'just', 'justin', 'justmet', 'justsaying', 'juts', 'jwtatl', 'jzsxsw', 'kara', 'karaoke', 'karateka', 'kawasaki', 'keep', 'keepaustinweird', 'keeping', 'keeps', 'keg', 'kek', 'ken', 'kenny', 'ketchsx', 'keyboard', 'keynote', 'keys', 'keywords', 'khan', 'khoi', 'kick', 'kickass', 'kicked', 'kicking', 'kid', 'kiddie', 'kidding', 'kids', 'kiiiiiilling', 'kill', 'killcommunity', 'killer', 'killers', 'killing', 'kind', 'kinda', 'kindle', 'king', 'kingston', 'kiosk', 'kirkus', 'kiss', 'kit', 'klick', 'klm', 'knackered', 'knew', 'knickers', 'knife', 'knockout', 'know', 'knowing', 'knowledge', 'known', 'knows', 'korean', 'korine', 'kthxbai', 'kudos', 'kweli', 'kyping', 'l8er', 'la', 'lab', 'labs', 'lack', 'ladies', 'lady', 'lake', 'lame', 'land', 'landlords', 'landmark', 'landscapes', 'lanyrd', 'lap', 'laptop', 'laptops', 'large', 'larger', 'largest', 'larry', 'laser', 'last', 'lasts', 'lat', 'late', 'lately', 'later', 'latest', 'latina', 'latinasintech', 'latism', 'latitude', 'laugh', 'laughed', 'launch', 'launched', 'launches', 'launching', 'launchrock', 'laurieshook', 'lava', 'lavelle', 'law', 'laws', 'lax', 'layed', 'layer', 'lazy', 'lazyweb', 'lbs', 'lead', 'leading', 'league', 'leaked', 'leaning', 'leanstartup', 'learn', 'learned', 'learning', 'leash', 'leasing', 'least', 'leather', 'leave', 'leaves', 'leaving', 'left', 'legacy', 'lego', 'leider', 'leisure', 'leisurely', 'lemon', 'leopard', 'less', 'lessons', 'let', 'lets', 'letschangetheworld', 'letter', 'letting', 'letushopenot', 'level', 'leveraging', 'lewis', 'liberty', 'libraries', 'library', 'licked', 'lie', 'life', 'lifeless', 'lifelinetotheworld', 'lifetime', 'light', 'lightbox', 'lightbulb', 'lighters', 'likability', 'like', 'likeability', 'liked', 'likely', 'likes', 'liking', 'lil', 'limit', 'limited', 'limp', 'lindsay', 'line', 'lines', 'lineup', 'lining', 'link', 'linking', 'links', 'lisa', 'list', 'listen', 'listened', 'listening', 'literally', 'litle', 'little', 'live', 'liveblog', 'lives', 'livesteam', 'livetapp', 'living', 'livingthedream', 'll', 'load', 'loaded', 'loading', 'loathe', 'lobby', 'lobbying', 'local', 'localmind', 'locals', 'locating', 'location', 'locations', 'lockers', 'lockout', 'logic', 'logical', 'login', 'logo', 'logos', 'lol', 'lonely', 'lonelyplanet', 'long', 'longer', 'longlinesbadux', 'look', 'lookalike', 'looked', 'looking', 'lookingforwardtothemusicfest', 'looks', 'loose', 'looseorganizations', 'lord', 'lordy', 'lorry', 'lose', 'losers', 'losing', 'lost', 'lot', 'lots', 'lottery', 'loud', 'louisiana', 'lounge', 'lousy', 'love', 'loved', 'lovefresh', 'loveher', 'lovely', 'lovemusicapi', 'lovers', 'loves', 'lovesit', 'lovin', 'loving', 'lowest', 'loyalty', 'lp', 'lt', 'luck', 'lucky', 'ludicon', 'lug', 'lugging', 'lunch', 'lust', 'lustre', 'luxury', 'lxh', 'ly', 'lying', 'lynn', 'ma', 'mac', 'macallan', 'macbook', 'macbookpro', 'macbooks', 'macchiato', 'machine', 'machines', 'mackbook', 'macs', 'macys', 'mad', 'made', 'madebymany', 'madness', 'mae', 'maes', 'magazine', 'magazines', 'maggie', 'magic', 'maglight', 'magnet', 'magnetic', 'magnifying', 'mags', 'major', 'majority', 'make', 'makery', 'makes', 'makeshift', 'making', 'malady', 'malbonster', 'mall', 'malt', 'man', 'manage', 'management', 'manager', 'managing', 'manhandling', 'mania', 'manor', 'mantra', 'many', 'map', 'mapped', 'mappers', 'mapping', 'mapquest', 'maps', 'mar', 'marcelosomers', 'march', 'margarita', 'margin', 'marisa', 'marissa', 'marissagoogle', 'marissamayer', 'marissameyer', 'mark', 'market', 'marketer', 'marketing', 'marketplace', 'markets', 'mart', 'martinis', 'marty', 'marys', 'masha', 'mashable', 'mashbash', 'mass', 'masses', 'massive', 'mastered', 'matching', 'mater', 'math', 'matt', 'matter', 'matthew', 'maudies', 'mavis', 'may', 'maybe', 'mayer', 'mayers', 'mayor', 'mbp', 'mccannsxsw', 'mdw', 'me', 'mealtime', 'mean', 'meaning', 'meaningful', 'means', 'meant', 'measurement', 'measuring', 'meat', 'mecca', 'mechanics', 'media', 'meet', 'meeting', 'meetings', 'meets', 'meetup', 'meetups', 'mega', 'megastore', 'meh', 'mekong', 'mel', 'member', 'memolane', 'memories', 'men', 'mention', 'mentioned', 'mentionn', 'mentionr', 'merchant', 'mercy', 'message', 'messages', 'messaging', 'messed', 'messenger', 'messina', 'met', 'metaphor', 'methinks', 'mexican', 'mhealth', 'miamibeach', 'mic', 'michael', 'michaelpiliero', 'microformats', 'microsoft', 'mid', 'midday', 'middle', 'midem', 'midnight', 'midst', 'midway', 'mifi', 'might', 'mike', 'miles', 'military', 'mill', 'miller', 'million', 'millions', 'min', 'mind', 'mindjet', 'mindmanager', 'minds', 'mindshare', 'mine', 'mini', 'minimalistprogramming', 'minor', 'mint', 'minute', 'minutes', 'miracle', 'mirroring', 'miss', 'missed', 'missing', 'mission', 'misstatements', 'mistake', 'mistakes', 'mister', 'mitharvard', 'mix', 'mixed', 'mixing', 'mk', 'mkt', 'mktg', 'mmm', 'mmod', 'mnbuzz', 'mngr', 'mobil', 'mobile', 'mobilefarm', 'mobileroadie', 'mobs', 'mock', 'mocked', 'mocking', 'mode', 'model', 'models', 'moderator', 'mom', 'moma', 'moment', 'momento', 'moments', 'mommy', 'mon', 'monday', 'mondays', 'monetization', 'money', 'monger', 'monitor', 'monopoly', 'monster', 'month', 'months', 'mood', 'moody', 'moonbot', 'moonshine', 'mophie', 'more', 'moreknowledge', 'morning', 'morphie', 'mosaicxm', 'most', 'mostly', 'motherboard', 'mothers', 'motivator', 'motorola', 'mountain', 'mounts', 'mouse', 'move', 'moves', 'movie', 'movies', 'moving', 'mozilla', 'mp', 'mp3', 'mq', 'mr', 'mrs', 'msft', 'mt', 'much', 'mullenweg', 'multiple', 'muro', 'murphy', 'museum', 'museums', 'music', 'musica', 'musicians', 'musicviz', 'musiek', 'musik', 'musique', 'must', 'mute', 'muting', 'mwrc11', 'my', 'myegc', 'mylunch', 'mypov', 'myself', 'myspace', 'mystery', 'nab', 'nailed', 'naive', 'name', 'named', 'naomi', 'nat', 'native', 'natural', 'navigating', 'navigation', 'nba', 'nc', 'ncaa', 'near', 'nearly', 'neat', 'need', 'needle', 'needs', 'neither', 'nerd', 'nerdbird', 'nerdcore', 'nerdheaven', 'nerdiest', 'nerds', 'nerdsunite', 'nerdy', 'ness', 'netbook', 'netflix', 'netflixiphone', 'network', 'networking', 'networks', 'neumann', 'never', 'new', 'newapplestoreaustin', 'newest', 'newly', 'news', 'newsapps', 'newspaper', 'newspapers', 'newtrent', 'next', 'nextflix', 'nexus', 'nfc', 'nfl', 'nhk', 'nice', 'nicely', 'niceness', 'nick', 'nieuwe', 'nifty', 'night', 'nightjar', 'nike', 'nine', 'nineties', 'ning', 'ninjafinder', 'no', 'nobody', 'noes', 'nokia', 'nokiaconnects', 'non', 'nonprofit', 'nonprofits', 'noon', 'nope', 'nor', 'normal', 'not', 'notch', 'note', 'notes', 'notetaker', 'notevenstartedyet', 'nothing', 'notice', 'noticed', 'notionink', 'notpouting', 'notsomuch', 'nottheipad2', 'novelty', 'novideo', 'now', 'nowhammies', 'npr', 'nptech', 'nten', 'ntn', 'nuances', 'nudgenudge', 'numbassonfloor', 'number', 'nur', 'nuts', 'nutshell', 'nutters', 'nvidia', 'nxt', 'nyc', 'nyt', 'object', 'objective', 'obs', 'observation', 'observations', 'observer', 'obsessed', 'obsolete', 'obv', 'obvious', 'obviously', 'occasional', 'of', 'off', 'offer', 'offered', 'offering', 'offers', 'office', 'officer', 'official', 'officially', 'offline', 'offsite', 'often', 'ogilvy', 'ogilvynotes', 'oh', 'oil', 'ok', 'okay', 'ol', 'old', 'oldschool', 'oldsko0l', 'omaha', 'omfg', 'omg', 'omgz', 'omitting', 'on', 'once', 'one', 'ones', 'online', 'only', 'onto', 'ooing', 'oooh', 'ooooo', 'open', 'openbeta', 'openbeta6', 'opened', 'openexhibits', 'opening', 'opens', 'operators', 'opinions', 'opportunity', 'opposite', 'optimistic', 'optimized', 'optimum', 'options', 'optiscan', 'or', 'orange', 'order', 'ordered', 'ordering', 'ordinance', 'org', 'organic', 'organically', 'organization', 'organize', 'organized', 'organizing', 'original', 'orkut', 'orlando', 'orly', 'oscars', 'osmpw', 'ossum', 'other', 'others', 'otherwise', 'ouch', 'our', 'ours', 'out', 'outbrain', 'outdid', 'outlandish', 'outlet', 'outlook', 'outs', 'outside', 'over', 'overall', 'overblown', 'overcome', 'overflow', 'overheard', 'overheating', 'overlaid', 'overlapping', 'overlay', 'overload', 'overshadowing', 'oversized', 'overtaken', 'overview', 'overwhelming', 'owl', 'owllove', 'own', 'owner', 'owners', 'owns', 'oy', 'pac', 'pacific', 'pack', 'packed', 'packing', 'packrat', 'packs', 'padless', 'page', 'pagemaker', 'pages', 'paid', 'painful', 'pair', 'paired', 'pak', 'pakistan', 'palette', 'palsy', 'pandora', 'panel', 'panelist', 'panelists', 'panels', 'panhandling', 'panic', 'panned', 'panning', 'pants', 'paolo', 'papa', 'papasangre', 'paper', 'paperless', 'papyrus', 'para', 'parachute', 'parentheses', 'parents', 'pariah', 'park', 'parked', 'part', 'partial', 'participants', 'participating', 'parties', 'partner', 'partnerhub', 'partnership', 'parts', 'party', 'partying', 'partytweets', 'passage', 'passenger', 'passes', 'passing', 'passport', 'passì', 'past', 'paste', 'patch', 'path', 'patience', 'paul', 'pauly', 'pause', 'pavement', 'pay', 'paying', 'payingwithdata', 'payments', 'paypal', 'pc', 'pcbuzz', 'pcma', 'pdanet', 'pdf', 'pdx', 'peaked', 'pearl', 'peddle', 'pedicab', 'peek', 'peeps', 'peer', 'pen', 'penetrates', 'pengairborne', 'penguin', 'people', 'pep', 'per', 'percent', 'percentage', 'perfect', 'perfectly', 'performance', 'perhaps', 'periscope', 'permanent', 'permanently', 'perserverance', 'person', 'personal', 'personalized', 'peter', 'petition', 'petricone', 'petting', 'phenomenal', 'phew', 'phone', 'phones', 'photo', 'photobooth', 'photoes', 'photos', 'photosharing', 'physical', 'pi', 'pic', 'pick', 'picked', 'picking', 'pickmeupanipad2', 'pics', 'picture', 'pictures', 'pie', 'piece', 'pig', 'pigfucker', 'pilhofer', 'pillow', 'pinoy', 'piping', 'piss', 'pissedimnotgoingtosxsw', 'pissing', 'pit', 'pitch', 'pitchforks', 'pitfalls', 'pitted', 'pix', 'pixel', 'pixelated', 'pixels', 'pixieengine', 'place', 'places', 'plaid', 'plain', 'plan', 'plancast', 'plane', 'planely', 'planes', 'planet', 'planner', 'planning', 'plans', 'planting', 'planzai', 'plate', 'platform', 'play', 'playback', 'playbook', 'played', 'player', 'players', 'playhopskoch', 'playing', 'playstation', 'playsxsw', 'please', 'pleased', 'plenty', 'plied', 'pls', 'plug', 'pluged', 'plugin', 'plunge', 'plus', 'pm', 'pnid', 'pocket', 'podcast', 'poetry', 'point', 'pointer', 'points', 'police', 'policy', 'politics', 'pollak', 'ponies', 'poo', 'pool', 'poole', 'poor', 'poos', 'pop', 'popped', 'popping', 'popplet', 'poppop', 'popular', 'populous', 'popup', 'popupshop', 'popupstore', 'por', 'porn', 'portable', 'porting', 'posed', 'position', 'positioning', 'positive', 'positively', 'positives', 'possibility', 'possible', 'possibly', 'post', 'posted', 'postpc', 'pot', 'potential', 'potentially', 'pour', 'poursite', 'power', 'powerful', 'powerhouse', 'powering', 'powermat', 'powermatteam', 'powermattteam', 'pp', 'ppl', 'pr', 'practice', 'pragmatic', 'pre', 'precedent', 'precommerce', 'prefer', 'preference', 'preferences', 'preferrably', 'preferred', 'prefers', 'premature', 'premiere', 'premium', 'prep', 'preparation', 'preparations', 'prepared', 'preparing', 'prepping', 'presence', 'present', 'presentation', 'presented', 'presenters', 'presenting', 'preso', 'press', 'pressie', 'pressure', 'pretty', 'prettycool', 'preview', 'previews', 'previous', 'price', 'prices', 'pride', 'princess', 'principles', 'print', 'printed', 'prints', 'priorities', 'priority', 'privacy', 'private', 'prize', 'prizes', 'pro', 'prob', 'probably', 'problem', 'process', 'prodmktg', 'produced', 'producers', 'product', 'products', 'professionals', 'profile', 'profits', 'program', 'programming', 'progressbar', 'progression', 'project', 'project314', 'projecting', 'projects', 'promises', 'promo', 'promote', 'promotion', 'prompt', 'proof', 'propping', 'proprietary', 'props', 'protect', 'protecting', 'protip', 'protocol', 'proud', 'provide', 'provided', 'providing', 'proving', 'ps', 'pseudoretweet', 'psfk', 'pst', 'psych', 'psyched', 'psyches', 'pub', 'pubcamp', 'public', 'publishers', 'publishing', 'pull', 'pulling', 'pumped', 'pumps', 'pun', 'puppy', 'purchase', 'purchased', 'purchasers', 'purchases', 'purchasing', 'pure', 'puregenius', 'purpose', 'push', 'pushed', 'pusher', 'pushio', 'pushsnowboarding', 'put', 'puts', 'putting', 'puzzles', 'q7a', 'qa', 'qagb', 'qho', 'qr', 'qrafter', 'qrank', 'qrcode', 'qs', 'quadroid', 'quake', 'qualcomm', 'qualified', 'quality', 'quantity', 'quantter', 'quarantined', 'quarter', 'quarters', 'que', 'question', 'questioner', 'questions', 'queue', 'quibids', 'quibidswin', 'quick', 'quicker', 'quickly', 'quiet', 'quinn', 'quit', 'quite', 'quot', 'quotable', 'quotables', 'quotes', 'race', 'rachael', 'rad', 'radical', 'radio', 'raffled', 'raffling', 'rage', 'rails', 'rain', 'rainjacket', 'raised', 'raises', 'rallying', 'ran', 'rana', 'random', 'randomly', 'range', 'rank', 'ranked', 'ranking', 'rankings', 'rant', 'rare', 'rate', 'rates', 'rather', 'rating', 'ratings', 'ratio', 'ray', 're', 'reach', 'reached', 'reacquainted', 'read', 'reader', 'readership', 'reading', 'ready', 'real', 'realistic', 'reality', 'realize', 'realized', 'realizing', 'realllllllly', 'really', 'realtime', 'rear', 'reason', 'reasonable', 'reasoning', 'reasons', 'rebecca', 'rebeltv', 'rebranded', 'recap', 'received', 'recharge', 'recharging', 'recipe', 'recipes', 'recipient', 'reclaimed', 'recognition', 'recognize', 'recomds', 'recommend', 'recommendation', 'recommendations', 'recommended', 'recommends', 'record', 'recorder', 'recos', 'recovery', 'recreated', 'recs', 'recycled', 'red', 'redbox', 'redbull', 'reddit', 'rediculous', 'reel', 'ref', 'referrals', 'refine', 'refresh', 'refrigerator', 'regarded', 'regel', 'regions', 'register', 'registers', 'registrant', 'regrets', 'regretting', 'regular', 'regularly', 'rei', 'reid', 'reilly', 'reily', 'rejection', 'related', 'relation', 'relationship', 'relaxed', 'relaxing', 'release', 'released', 'releases', 'releasing', 'relevant', 'relic', 'relief', 'relies', 'religion', 'relinquish', 'relive', 'reliving', 'remaining', 'rematch', 'remedied', 'remember', 'remembered', 'reminding', 'removable', 'remove', 'rendering', 'renders', 'repair', 'replaced', 'replacement', 'replacing', 'replenished', 'replicate', 'replies', 'report', 'reporting', 'reports', 'repressed', 'reproducing', 'republic', 'reputation', 'rerouted', 'rescuing', 'research', 'resetting', 'resist', 'resonance', 'resource', 'resourceful', 'respect', 'respectfully', 'respecting', 'response', 'responses', 'responsibility', 'rest', 'restaurant', 'restaurants', 'restful', 'resting', 'restore', 'restored', 'restraunts', 'result', 'resulting', 'results', 'resume', 'retail', 'retiring', 'retrollect', 'return', 'retweet', 'retweeting', 'revealed', 'reveals', 'revelations', 'revenge', 'revenue', 'review', 'reviews', 'revolt', 'revolution', 'revolutionary', 'revolutions', 'reward', 'rewards', 'rewardswagon', 'rf', 'rhizome', 'richard', 'ridculous', 'ride', 'rides', 'ridic', 'ridicule', 'ridiculous', 'ridiculously', 'rig', 'rigeur', 'right', 'rightfully', 'rim', 'rimmed', 'ringing', 'rinna', 'riots', 'rip', 'ripped', 'ripping', 'rise', 'rise_austin', 'rite', 'river', 'rji', 'rm', 'road', 'roadie', 'roaming', 'robot', 'robots', 'rock', 'rockaroke', 'rocked', 'rockin', 'rocking', 'rocks', 'rockstache', 'role', 'roll', 'roof', 'room', 'rosso', 'rotational', 'round', 'route', 'routes', 'routing', 'row', 'rows', 'rpg', 'rsq', 'rsvp', 'rt', 'rub', 'rubbing', 'rule', 'rules', 'rumor', 'rumored', 'rumors', 'rumours', 'run', 'runaround', 'running', 'runs', 'rww', 'saatchiny', 'saber', 'sabotaged', 'sad', 'sadly', 'safari', 'said', 'sale', 'sales', 'salesperson', 'salon', 'sam', 'same', 'sampler', 'samsung', 'samsungmobileus', 'san', 'sandwich', 'sandwiched', 'sangre', 'sans', 'sapient', 'sat', 'saturday', 'sauce', 'save', 'savebrands', 'saved', 'saves', 'saveustechies', 'saving', 'savings', 'savvy', 'saw', 'say', 'saying', 'says', 'saysshewithoutanipad', 'scale', 'scan', 'scans', 'scarborough', 'scarbrough', 'scared', 'scarfing', 'scary', 'scavenger', 'scene', 'scenes', 'scepticism', 'sched', 'schedule', 'scheduled', 'scheduler', 'schedules', 'scheduling', 'schemas', 'school', 'schools', 'schtuff', 'schwag', 'science', 'scientific', 'scoping', 'score', 'scored', 'scoremore', 'scouts', 'screamed', 'screams', 'screen', 'screening', 'screenings', 'sd', 'sea', 'search', 'searchable', 'searches', 'searching', 'season', 'seat', 'seated', 'seats', 'seattle', 'sec', 'second', 'seconds', 'secret', 'security', 'see', 'seeing', 'seem', 'seemed', 'seemingly', 'seems', 'seen', 'seenocreepy', 'sees', 'seesmic', 'select', 'selected', 'selection', 'self', 'selfish', 'sell', 'selling', 'sells', 'sem', 'semantic', 'send', 'sending', 'sense', 'sent', 'seo', 'separate', 'september', 'serendipity', 'serious', 'seriously', 'seriousness', 'serv', 'serve', 'served', 'server', 'servers', 'serves', 'service', 'services', 'sesh', 'session', 'sessions', 'set', 'seta', 'sets', 'setting', 'settle', 'settling', 'setup', 'several', 'severe', 'severely', 'sfo', 'shade', 'shades', 'shakespeare', 'shall', 'shallow', 'shame', 'shamed', 'shameless', 'shaping', 'share', 'shareable', 'shared', 'sharers', 'sharing', 'sharp', 'shat', 'shatter', 'she', 'sheen', 'sheeple', 'shell', 'shelves', 'sheraton', 'shift', 'shill', 'shiner', 'shinmy', 'shiny', 'shipment', 'shipments', 'ships', 'shirt', 'shit', 'shite', 'shitty', 'shocked', 'shoot', 'shooting', 'shop', 'shops', 'short', 'shortcuts', 'shortening', 'shortly', 'shot', 'shotgun', 'should', 'shoulda', 'shoulder', 'shouldn', 'shout', 'shouts', 'show', 'showcase', 'showcased', 'showcases', 'showed', 'showing', 'shows', 'showusyouricrazy', 'shrink', 'shuffling', 'shut', 'sick', 'side', 'sides', 'sigh', 'sighting', 'sightings', 'sign', 'signal', 'signals', 'signed', 'signing', 'signs', 'silicon', 'sillier', 'silly', 'silver', 'simple', 'simply', 'simultaneously', 'sin', 'since', 'singing', 'single', 'singularity', 'sipping', 'sis', 'sister', 'sit', 'sitby', 'site', 'sites', 'sitting', 'six', 'sixth', 'size', 'skateboards', 'skepticism', 'sketch', 'sketchy', 'skiers', 'skill', 'skillfully', 'skills', 'skinny', 'skip', 'skulls', 'skyfire', 'skynet', 'skype', 'slap', 'slated', 'sleek', 'sleep', 'sleepy', 'sleeves', 'slice', 'sliced', 'slick', 'slides', 'slightly', 'slim', 'slips', 'sloanxsw', 'slow', 'slower', 'slowly', 'slowpoke', 'slp', 'smackdown', 'small', 'smallbiz', 'smaller', 'smart', 'smartcover', 'smarter', 'smartest', 'smartphone', 'smartphones', 'smartthings', 'smashed', 'smcdallas', 'smcomedyfyeah', 'smell', 'smileyparty', 'smm', 'smmnextgen', 'smokes', 'smooth', 'smtravel', 'smudgy', 'smugness', 'smurf', 'smut', 'smvis', 'smyle', 'sn', 'snagged', 'snakeheead', 'snap', 'snapping', 'snarky', 'sneakers', 'sneaky', 'so', 'socbiz', 'social', 'socialfuel', 'socially', 'socialmedia', 'socialmediabum', 'socialmuse', 'socialviewing', 'society', 'socks', 'socnet', 'softball', 'softlayer', 'software', 'sold', 'solely', 'solid', 'solo', 'solution', 'solutions', 'solves', 'solving', 'some', 'somebody', 'someday', 'somehow', 'someone', 'someones', 'something', 'somewhere', 'song', 'songs', 'sonos', 'sony', 'soo', 'soon', 'sore', 'sorry', 'sort', 'sorta', 'sorted', 'sound', 'soundcloud', 'sounding', 'sounds', 'source', 'south', 'southby', 'southpaw', 'southwest', 'space', 'spanking', 'spark', 'spasmatics', 'spazmatic', 'spazmatics', 'speak', 'speakeasy', 'speaking', 'speaks', 'special', 'specific', 'speech', 'speed', 'speedup', 'spell', 'spend', 'spending', 'spent', 'spider', 'spilled', 'spin', 'spinning', 'spirit', 'spoiled', 'spoke', 'spoken', 'sponso', 'sponsored', 'spontaniety', 'sporting', 'spot', 'spots', 'spotted', 'spread', 'spring', 'sprinkle', 'sprint', 'spy', 'sq', 'square', 'squeal', 'squeeze', 'srsly', 'st', 'stabilizer', 'stacks', 'staff', 'stage', 'stand', 'standard', 'standardization', 'standing', 'star', 'starbu', 'starbucks', 'staring', 'starry', 'stars', 'start', 'started', 'starting', 'starts', 'startup', 'startupbus', 'startups', 'statement', 'states', 'station', 'stations', 'stats', 'statuses', 'stay', 'staying', 'stays', 'steady', 'stealing', 'steals', 'steampunk', 'steamy', 'stellar', 'step', 'stepped', 'stereo', 'sters', 'steve', 'stickers', 'still', 'stillman', 'stock', 'stogies', 'stoked', 'stole', 'stolen', 'stood', 'stop', 'stopped', 'stops', 'storage', 'store', 'stores', 'stories', 'storm', 'story', 'straight', 'strange', 'strangeproblems', 'stranger', 'strangers', 'straps', 'strategy', 'straw', 'stream', 'streaming', 'streams', 'street', 'streetview', 'strength', 'stress', 'stretches', 'striking', 'strip', 'strive', 'stroke', 'strong', 'structured', 'struggle', 'strums', 'stuck', 'studentsforcleanwater', 'studies', 'studios', 'study', 'studying', 'stuff', 'stumbledupon', 'stumbling', 'stunning', 'stunt', 'stupid', 'style', 'stylish', 'suasxsw', 'subscription', 'subscriptions', 'succeed', 'success', 'successful', 'succumb', 'such', 'suck', 'suckas', 'sucked', 'suckling', 'sucks', 'suddenly', 'suffered', 'suffering', 'suggest', 'suggestion', 'suggestions', 'suicidal', 'suicide', 'sullivan', 'sum', 'summer', 'summit', 'sun', 'sunday', 'sundayswagger', 'sunglasses', 'sunny', 'suns', 'super', 'superbia', 'supply', 'support', 'suppose', 'supposed', 'supposedly', 'sure', 'surely', 'surface', 'surpassed', 'surplus', 'surprise', 'surprises', 'surrounded', 'surui', 'survey', 'survival', 'survive', 'survived', 'suspense', 'sustainability', 'sux', 'suxsw', 'svcs', 'swag', 'swarming', 'swarms', 'sweater', 'sweeeeet', 'sweeeet', 'sweepstakes', 'sweet', 'sweets', 'swift', 'swing', 'swish', 'swisher', 'switch', 'switches', 'swonderlin', 'swoon', 'swsurrogates', 'swsx', 'sxfl', 'sxflip', 'sxprotect', 'sxsh', 'sxsurrogates', 'sxsw', 'sxsw11', 'sxsw2011', 'sxsw4japan', 'sxswaccel', 'sxswbarcrawl', 'sxswbigbrands', 'sxswbuffalo', 'sxswchi', 'sxswfail', 'sxswgood', 'sxswh', 'sxswi', 'sxswk', 'sxswlatam', 'sxswmobileapps', 'sxswmoot', 'sxswmusic', 'sxswmymistake', 'sxswnui', 'sxswpass', 'sxswsa', 'sxswsex', 'sxswsmall', 'sxswtoolkit', 'sxtxstate', 'sxwsi', 'sxxpress', 'syked', 'symbian', 'symbol', 'sync', 'synced', 'synching', 'syncing', 'syncs', 'synergy', 'system', 'systems', 'taariq', 'tab', 'table', 'tables', 'tablet', 'tablets', 'taccsxsw', 'tacos', 'tag', 'tagging', 'take', 'takeaway', 'taken', 'takeover', 'takes', 'takin', 'taking', 'talent', 'talented', 'talib', 'talk', 'talked', 'talking', 'talks', 'tan', 'tap', 'tapworthy', 'target', 'task', 'tastes', 'tattoo', 'tattooed', 'taught', 'taunt', 'tax', 'taxi', 'tbalinas', 'tbwasxsw', 'tc', 'tchin', 'tdg', 'teach', 'teaching', 'team', 'team_android', 'teamandroid', 'teamandroidsxsw', 'teams', 'tear', 'teathering', 'tech', 'tech4good', 'tech_news', 'techcrunch', 'techenvy', 'techgeek', 'techie', 'techies', 'techiesunite', 'technews', 'technical', 'techno', 'technology', 'techrockstar', 'techsmith', 'tee', 'teeming', 'teeny', 'teeth', 'telegraph', 'teleporting', 'television', 'telework', 'tell', 'tells', 'temp', 'temperature', 'temperatures', 'temporary', 'tempt', 'temptation', 'tempted', 'tempting', 'ten', 'tenets', 'tent', 'teo', 'term', 'terminal', 'terms', 'terrible', 'test', 'tested', 'testing', 'tests', 'tether', 'tethering', 'texas', 'texasevery', 'text', 'texting', 'th', 'than', 'thank', 'thanks', 'thanksforthebrandedshades', 'thankyouecon', 'that', 'the', 'the_daily', 'theatre', 'theem', 'theft', 'thegogame', 'theindustryparty', 'their', 'theirs', 'them', 'theme', 'themed', 'themselves', 'then', 'thenextweb', 'theplatform', 'ther', 'therapy', 'there', 'thereby', 'therefore', 'these', 'thewildernessdowntown', 'they', 'thick', 'thier', 'thin', 'thing', 'things', 'thingsthatdontgotogether', 'think', 'thinking', 'thinks', 'thinmints', 'thinner', 'third', 'thirsty', 'this', 'thisisdare', 'tho', 'thomas', 'thoora', 'those', 'though', 'thought', 'thoughtful', 'thoughts', 'thousands', 'threat', 'three', 'threw', 'thrilled', 'through', 'throughout', 'throw', 'throwin', 'throwing', 'thru', 'tht', 'thumbs', 'thunder', 'thursday', 'thus', 'thx', 'ticket', 'tidbit', 'tiff', 'tigerblood', 'til', 'till', 'tim', 'timberlake', 'time', 'timechange', 'timeline', 'timely', 'times', 'timing', 'tinkering', 'tiny', 'tinyurl', 'tip', 'tips', 'tis', 'title', 'titles', 'tix', 'tkts', 'tm', 'tme', 'tmobile', 'tmr', 'tmsxsw', 'tnw', 'tnx', 'to', 'toast', 'today', 'together', 'told', 'tomlinson', 'tomorrow', 'ton', 'tonchidot', 'tonigh', 'tonight', 'tons', 'too', 'toocoolforsxswanyway', 'toodamnlucky', 'took', 'tool', 'toolkit', 'toolongforme', 'tools', 'toooo', 'top', 'topicality', 'topics', 'topnews', 'tops', 'topspin', 'torch', 'tore', 'torture', 'torturous', 'total', 'totalitarian', 'totally', 'toting', 'touch', 'touched', 'touching', 'touchingstories', 'tough', 'tougher', 'toured', 'tournament', 'towards', 'towel', 'town', 'toy', 'track', 'tracker', 'trackpads', 'tracks', 'tractor', 'trade', 'traded', 'tradeshow', 'traffic', 'trailer', 'train', 'trajan', 'tramplings', 'transfer', 'transient', 'transition', 'translated', 'transparency', 'transparently', 'trashy', 'trauma', 'travel', 'travelers', 'traveling', 'traveller', 'treatment', 'trenches', 'trend', 'trending', 'trends', 'tribes', 'tricked', 'tried', 'tries', 'trigger', 'trip', 'tripping', 'tron', 'trophy', 'trouble', 'truck', 'trucks', 'true', 'truly', 'trumping', 'trumps', 'trust', 'trusted', 'trustworthiness', 'truth', 'try', 'trying', 'ts', 'tshirt', 'tsunami', 'tt', 'tub', 'tube', 'tuesday', 'tumblr', 'tunage', 'tune', 'tuned', 'tunehopper', 'tunes', 'turing', 'turkey', 'turn', 'turned', 'turning', 'turns', 'tv', 'tveverywhere', 'tvontheradio', 'tvs', 'tweeps', 'tweet', 'tweetcaster', 'tweetdeck', 'tweeted', 'tweethouse', 'tweetie', 'tweetignite', 'tweeting', 'tweets', 'tweetup', 'twice', 'twit', 'twitpic', 'twitter', 'twittering', 'twitterpower', 'two', 'tx', 'tye', 'type', 'typing', 'tyson', 'uber', 'uberguide', 'ubersocial', 'ubertwitter', 'ubiquitous', 'ubiquity', 'ubuntu', 'ugh', 'ughhh', 'ui', 'um', 'umassjour', 'umm', 'ummmm', 'umshini', 'un', 'una', 'unabashed', 'unadulterated', 'unbearable', 'unbelievable', 'unboxing', 'uncategorized', 'uncharged', 'unconfirmed', 'under', 'underestimate', 'underneath', 'understand', 'understanding', 'underway', 'underwire', 'undoubtedly', 'unequipped', 'unexpected', 'ungrateful', 'unimitated', 'unique', 'unite', 'united', 'units', 'universe', 'unleash', 'unless', 'unlisted', 'unloaded', 'unloading', 'unlockable', 'unlocking', 'unoffic', 'unofficial', 'unpack', 'unpaid', 'unreal', 'unscientific', 'unsix', 'unstable', 'untapped', 'until', 'unveil', 'unveiled', 'unveiling', 'unveils', 'uosxsw', 'up', 'upbeat', 'upc', 'update', 'updated', 'updates', 'updating', 'upgrade', 'upgrading', 'upload', 'uppward', 'ups', 'upset', 'upside', 'ur', 'urs', 'urthots', 'us', 'usa', 'usability', 'usage', 'usb', 'usdes', 'use', 'used', 'useful', 'usefulness', 'useless', 'user', 'users', 'uses', 'usguys', 'using', 'ustream', 'usual', 'usurped', 'utilize', 'utter', 'ux', 'uxdes', 'uzu', 'v1', 'v2', 'v3', 'v5', 'vacation', 'valid', 'valley', 'valuable', 'value', 'values', 'vast', 'vb', 'vcards', 've', 'vector', 'vectors', 'vegan', 'vegas', 'vending', 'venturebeat', 'venue', 'venues', 'ver', 'verizon', 'verpixelungsrecht', 'version', 'versions', 'very', 'veryslow', 'vestibule', 'veterans', 'via', 'viagra', 'vibe', 'vicariously', 'victims', 'vid', 'video', 'videogame', 'videogames', 'videos', 'vids', 'view', 'view512', 'viewed', 'viewing', 'views', 'vinh', 'vintage', 'vip', 'virgin', 'virginity', 'virtual', 'virtually', 'virtualoffice', 'virtualwallet', 'visigoths', 'visit', 'visiting', 'visitors', 'visits', 'visual', 'visualization', 'visualizing', 'vmware', 'voice', 'voicefeed', 'volume', 'voluntarily', 'volunteers', 'vortex', 'vote', 'voxpop', 'vp', 'vs', 'vuelta', 'vufinders', 'vuvuzela', 'w00t', 'waaaaaa', 'wack', 'wait', 'waited', 'waiting', 'wakeup', 'wal', 'walk', 'walked', 'walkin', 'walking', 'walks', 'wall', 'wallace', 'walmart', 'wam', 'wandered', 'wanderer', 'wanna', 'wannabe', 'want', 'wanted', 'wanting', 'wants', 'war', 'warmer', 'warmth', 'warning', 'wars', 'wary', 'was', 'wasn', 'waste', 'wasted', 'wasting', 'watch', 'watched', 'watching', 'water', 'waterproof', 'watson', 'wave', 'way', 'ways', 'waze', 'we', 'wearing', 'weasel', 'weather', 'web', 'web3', 'web30', 'webdoc', 'webkit', 'webmail', 'webmasters', 'website', 'websites', 'webvisions', 'wed', 'week', 'weekend', 'weeks', 'weeping', 'weight', 'weinschenk', 'weird', 'welcome', 'welivehere', 'well', 'went', 'were', 'weren', 'wesley83', 'weve', 'wew', 'whale', 'what', 'whatcha', 'when', 'where', 'whether', 'which', 'while', 'whimsical', 'white', 'whiteboarding', 'who', 'whoa', 'whole', 'whoooooo', 'whoops', 'whowillrise', 'whrrl', 'why', 'wi', 'wider', 'widfy', 'widgets', 'wife', 'wifi', 'wii', 'wil', 'wild', 'wilderness', 'will', 'williams', 'willing', 'willpay', 'willpower', 'wilting', 'win', 'winamp', 'windows', 'wine', 'wings', 'winner', 'winners', 'winning', 'wins', 'winsåê', 'winsåêsxsw', 'wintel', 'winwin', 'wipes', 'wired', 'wireless', 'wires', 'wise', 'wish', 'wishing', 'with', 'within', 'withme', 'without', 'witty', 'wjchat', 'wk', 'wkd', 'wkend', 'wknd', 'woah', 'wodpress', 'woes', 'wohooo', 'woke', 'wolfenstein', 'wolfram', 'woman', 'women', 'won', 'wonder', 'wonderful', 'wondering', 'wonders', 'woo', 'woohoo', 'wooooo', 'woops', 'woot', 'word', 'wordnerd', 'wordpress', 'words', 'work', 'worked', 'workers', 'workin', 'working', 'works', 'workspace', 'world', 'worlds', 'worldwide', 'worn', 'worried', 'worry', 'worse', 'worst', 'worth', 'worthwhile', 'wot', 'would', 'wouldn', 'wow', 'wowwwwww', 'wozniak', 'wp7', 'wr', 'wrap', 'wrapper', 'write', 'writer', 'writing', 'wrong', 'wrote', 'wsj', 'wssxsw', 'wtf', 'wth', 'wundertablet', 'wwsxsw', 'www', 'x6t1pi6av7', 'xbox', 'xd', 'xipad', 'xm', 'xmas', 'xml', 'xoom', 'xperia', 'xwave', 'ya', 'yai', 'yall', 'yawn', 'yay', 'yea', 'yeaayyy', 'yeah', 'year', 'years', 'yeasayer', 'yeay', 'yellow', 'yelp', 'yelping', 'yep', 'yer', 'yes', 'yesterday', 'yet', 'yield', 'yikes', 'yo', 'yobongo', 'yonkers', 'york', 'you', 'youneedthis', 'your', 'yours', 'yourself', 'youtube', 'yowza', 'yr', 'yrs', 'yummy', 'yup', 'zaarly', 'zaarlyiscoming', 'zagg', 'zaggle', 'zappos', 'zazzle', 'zazzlesxsw', 'zazzlsxsw', 'ze', 'zelda', 'zeldman', 'zero', 'zimride', 'zing', 'zip', 'zite', 'zms', 'zombies', 'zomg', 'zone', 'zoom', 'zzzs', '¼¼', 'á¾_î¾ð', 'äá', 'å_', 'åç', 'åçwhat', 'çü', 'èï', 'ðü', 'öý', 'ù_¾', 'û_', 'ûª', 'ûªll', 'ûªm', 'ûªs', 'ûªt', 'ûï', 'ûï35', 'ûïbuttons', 'ûïfoursquare', 'ûïline', 'ûïmore', 'ûïmute', 'ûïspecials', 'ûïthe', 'ûïview', 'ûò', 'ûòand', 'ûó', 'ûójust', 'ûólewis', 'ûóthe']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dwtgjTBeH0Ny"
      },
      "source": [
        "#### Tip: To see all available functions for an Object use dir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2n_iCcTNH0N0",
        "outputId": "0bada201-a327-492f-b534-1ffd3e26534d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dir(Vect)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setstate__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_char_ngrams',\n",
              " '_char_wb_ngrams',\n",
              " '_check_stop_words_consistency',\n",
              " '_check_vocabulary',\n",
              " '_count_vocab',\n",
              " '_get_param_names',\n",
              " '_get_tags',\n",
              " '_limit_features',\n",
              " '_more_tags',\n",
              " '_sort_features',\n",
              " '_stop_words_id',\n",
              " '_validate_custom_analyzer',\n",
              " '_validate_params',\n",
              " '_validate_vocabulary',\n",
              " '_white_spaces',\n",
              " '_word_ngrams',\n",
              " 'analyzer',\n",
              " 'binary',\n",
              " 'build_analyzer',\n",
              " 'build_preprocessor',\n",
              " 'build_tokenizer',\n",
              " 'decode',\n",
              " 'decode_error',\n",
              " 'dtype',\n",
              " 'encoding',\n",
              " 'fit',\n",
              " 'fit_transform',\n",
              " 'fixed_vocabulary_',\n",
              " 'get_feature_names',\n",
              " 'get_params',\n",
              " 'get_stop_words',\n",
              " 'input',\n",
              " 'inverse_transform',\n",
              " 'lowercase',\n",
              " 'max_df',\n",
              " 'max_features',\n",
              " 'min_df',\n",
              " 'ngram_range',\n",
              " 'preprocessor',\n",
              " 'set_params',\n",
              " 'stop_words',\n",
              " 'stop_words_',\n",
              " 'strip_accents',\n",
              " 'token_pattern',\n",
              " 'tokenizer',\n",
              " 'transform',\n",
              " 'vocabulary',\n",
              " 'vocabulary_']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ShA6D8jKH0N5"
      },
      "source": [
        "### Find out how many Positive and Negative emotions are there.\n",
        "\n",
        "Hint: Use value_counts on that column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "q7LAl5pzH0N6",
        "outputId": "6d718e8b-c59e-4042-d645-db0c057c78f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "pd.value_counts(df_Tweets['is_there_an_emotion_directed_at_a_brand_or_product'])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Positive emotion    2672\n",
              "Negative emotion     519\n",
              "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IUvgj0FoH0N9"
      },
      "source": [
        "###  Change the labels for Positive and Negative emotions as 1 and 0 respectively and store in a different column in the same dataframe named 'label'\n",
        "\n",
        "Hint: use map on that column and give labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YftKwFv7H0N9",
        "colab": {}
      },
      "source": [
        "df_Tweets['is_there_an_emotion_directed_at_a_brand_or_product'] = df_Tweets.is_there_an_emotion_directed_at_a_brand_or_product.map({'Positive emotion':1, 'Negative emotion':0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxqROCywljT_",
        "colab_type": "code",
        "outputId": "d7c0f1c9-a2b2-4ba4-b8d2-2e8ef0f17314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "df_Tweets['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2672\n",
              "0     519\n",
              "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK1LANinm6YS",
        "colab_type": "code",
        "outputId": "87df913d-2906-4c26-89e4-a6ee7e9e77b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "df_Tweets.columns"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['tweet_text', 'emotion_in_tweet_is_directed_at',\n",
              "       'is_there_an_emotion_directed_at_a_brand_or_product', 'text'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YErwYLCH0N_"
      },
      "source": [
        "### 9. Define the feature set (independent variable or X) to be `text` column and `labels` as target (or dependent variable)  and divide into train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lNkwrGgEH0OA",
        "colab": {}
      },
      "source": [
        "X = DTW\n",
        "y = df_Tweets['is_there_an_emotion_directed_at_a_brand_or_product']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpU0b-LavEvV",
        "colab_type": "code",
        "outputId": "4869505c-96b1-478f-81fb-99fa5e4011dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2393, 5648)\n",
            "(798, 5648)\n",
            "(2393,)\n",
            "(798,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q5nlCuaaH0OD"
      },
      "source": [
        "## 10. **Predicting the sentiment:**\n",
        "\n",
        "\n",
        "### Use Naive Bayes and Logistic Regression and their accuracy scores for predicting the sentiment of the given text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2AbVYssaH0OE",
        "colab": {}
      },
      "source": [
        "# Navives Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb = GaussianNB()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqE1CRqlobvm",
        "colab_type": "code",
        "outputId": "64369cfe-e0f9-489b-8f8d-d87427030662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nb.fit(X_train, y_train.values.ravel())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqpyFDp19lv3",
        "colab_type": "code",
        "outputId": "769163c6-6778-4975-92e1-ead43baec3e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "y_predictTest=nb.predict(X_test)\n",
        "y_predictTest"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMD3v_Fy9vgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_ds=np.where(nb.predict_proba(X_test)[:,1]> .35,1,0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbz_z8ub90aj",
        "colab_type": "code",
        "outputId": "5a4d1a7b-c46f-4524-8cd4-05e81f485e53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score,recall_score,confusion_matrix,precision_score,roc_curve,auc\n",
        "from sklearn import metrics\n",
        "\n",
        "recall_score(y_test,temp_ds,average=\"micro\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.768170426065163"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6gUlWZ394sL",
        "colab_type": "code",
        "outputId": "d3479e9a-cea3-48c8-b6d7-d8ac8f2f278b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "precision_score(y_test,temp_ds,average=\"micro\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.768170426065163"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy3rkOHYwEvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LogisticRegression\n",
        "reg = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5IyGZPowLXM",
        "colab_type": "code",
        "outputId": "06f04f73-c0f8-4b5c-ed7d-73c639f86aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "reg.fit(X_train, y_train)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1O4Th6bwPqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make class predictions for X_test\n",
        "y_pred_class = reg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUkdCyS-wTHV",
        "colab_type": "code",
        "outputId": "72f2215f-44c4-4f34-8835-1b57323f0603",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate accuracy of class predictions\n",
        "metrics.accuracy_score(y_test, y_pred_class)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.868421052631579"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSKwopXgwWQQ",
        "colab_type": "code",
        "outputId": "47df7e4b-bd7d-459f-fea8-0879f8034c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# print the confusion matrix\n",
        "metrics.confusion_matrix(y_test, y_pred_class)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 53,  77],\n",
              "       [ 28, 640]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sw-0B33tH0Ox"
      },
      "source": [
        "## 11. Create a function called `tokenize_predict` which can take count vectorizer object as input and prints the accuracy for x (text) and y (labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "okCTOs1TH0Oy",
        "colab": {}
      },
      "source": [
        "def tokenize_test(Vect):\n",
        "    x_train_DTW = Vect.fit_transform(X_train)\n",
        "    print('Features: ', X_train_DTW.shape[1])\n",
        "    X_test_DTW = vect.transform(X_test)\n",
        "    nb = MultinomialNB()\n",
        "    nb.fit(X_train_DTW, y_train)\n",
        "    y_pred_class = nb.predict(X_test_DTW)\n",
        "    print('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JxZ8jfPEH0O0"
      },
      "source": [
        "### Create a count vectorizer function which includes n_grams = 1,2  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kdCyAN_IH0O0",
        "colab": {}
      },
      "source": [
        "# include 1-grams and 2-grams\n",
        "Vect = CountVectorizer(ngram_range=(1, 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lunx7sVFhA-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "axepytmgH0O4"
      },
      "source": [
        "### 12. Create a count vectorizer function with stopwords = 'english'  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HToGkq7vH0O4",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iOIlJRxoH0O7"
      },
      "source": [
        "### 13. Create a count vectorizer function with stopwords = 'english' and max_features =300  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6fUhff-oH0O8",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S2KZNWVkH0PA"
      },
      "source": [
        "### 14. Create a count vectorizer function with n_grams = 1,2  and max_features = 15000  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3v9XD082H0PB",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "We3JK_SRH0PO"
      },
      "source": [
        "### 15. Create a count vectorizer function with n_grams = 1,2  and include terms that appear at least 2 times (min_df = 2)  and pass it to tokenize_predict function to print the accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fUHrfDCyH0PP",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}